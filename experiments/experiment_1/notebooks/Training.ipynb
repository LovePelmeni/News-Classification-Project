{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pickle\n",
    "from ..encoders import encoders\n",
    "from ..features import build_features\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ....src.models import train_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pbd on \n",
    "%load_ext line_profiler\n",
    "%load_ext tim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = open(\"../data/raw_data/category_dataset.pkl\", mode='rb')\n",
    "%timeit news_applications = pickle.load(dataset_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit news_applications = build_features.build_features(dataset=news_applications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = news_applications.drop(columns=['category'])\n",
    "y_data = news_applications['category']\n",
    "\n",
    "# splitting data \n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_data, y_data, stratify=y_data, test_size=0.3\n",
    ")\n",
    "\n",
    "# Merging variables \n",
    "training_set = pandas.concat([x_train, y_train], axis=1)\n",
    "testing_set = pandas.concat([x_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding dataset features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = encoders.DatasetEncoder()\n",
    "%timeit encoded_dataset = encoder.encode_dataset(dataset=news_applications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "\n",
    "models = {\n",
    "    \"lg\": LogisticRegression(),\n",
    "    \"gnb\": GaussianNB(),\n",
    "    \"bnb\": BernoulliNB(),\n",
    "}\n",
    "\n",
    "hyperparams = {\n",
    "    \"lg\": {},\n",
    "    \"gnb\": {},\n",
    "    \"bnb\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "for model_name, model in models.items():\n",
    "    score, best_model = train_model.fine_tune_model(\n",
    "        model=model,\n",
    "        training_set=training_set,\n",
    "        k_cross=5,\n",
    "        target_variable=\"category\",\n",
    "        hyperparams=hyperparams\n",
    "    )\n",
    "    if score > best_score:\n",
    "        rec_model = best_model \n",
    "\n",
    "print(\n",
    "    \"best model: %s\" % best_model,\n",
    "    \"best score: %s\" % best_score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion on baseline model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
