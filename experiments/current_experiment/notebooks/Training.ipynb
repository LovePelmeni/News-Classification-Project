{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import train_model\n",
    "import pandas\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pandas.read_csv(os.path.join(DATA_PATH, \"/processed_data/training_set.csv\"))\n",
    "validation_set = pandas.read_csv(os.path.join(DATA_PATH, \"/processed_data/validation_set.csv\"))\n",
    "testing_set = pandas.read_csv(os.path.join(DATA_PATH, \"/processed_data/testing_set.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the best baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.metrics import make_scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"lg\": LogisticRegression(),\n",
    "    \"gnb\": GaussianNB(),\n",
    "    \"bnb\": BernoulliNB(),\n",
    "}\n",
    "\n",
    "hyperparams = {\n",
    "    \"lg\": {},\n",
    "    \"gnb\": {},\n",
    "    \"bnb\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "metric = make_scorer(recall_score(average='macro'), greater_is_better=True)\n",
    "feature_importances = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    cv_results = RFECV(\n",
    "        estimator=model,\n",
    "        step=2,\n",
    "        min_features_to_select=4,\n",
    "        cv=StratifiedKFold(n_splits=5),\n",
    "        n_jobs=-1,\n",
    "        scoring=metric,\n",
    "    )\n",
    "    feature_importances[model_name] = {\n",
    "        'important_features': cv_results.cv_results_\n",
    "    }\n",
    "\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {}\n",
    "loss_function = make_scorer()\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    score, best_model = train_model.fine_tune_model(\n",
    "        k_cross=5,\n",
    "        training_set=training_set,\n",
    "        target_variable=\"category\",\n",
    "        hyperparams=hyperparams[model_name],\n",
    "        model=model,\n",
    "        loss_function_or_scorer_metric=metric,\n",
    "    )\n",
    "    output[model_name] = {\n",
    "        \"best_model\": best_model,\n",
    "        \"best_score\": score\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing output and choosing best baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model = output['gnb']['best_model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing model using cross-validation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X, Y = testing_set.drop(columns=['category']), testing_set['category']\n",
    "cv = cross_validate(\n",
    "    estimator=chosen_model,\n",
    "    scoring=metric,\n",
    "    X=testing_set,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True)\n",
    ")\n",
    "print('test metric score: %s' % cv['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating model performance according to baseline metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(chosen_model, open('../models/classifier.pkl', mode='wb'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
