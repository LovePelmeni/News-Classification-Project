{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Baseline Model Training & Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import train_model\n",
    "import pandas\n",
    "import pickle\n",
    "import os\n",
    "from baseline_requirements import metrics \n",
    "from text_classification import text\n",
    "\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pandas.read_csv(\"../data/processed_data/training_set.csv\")\n",
    "validation_set = pandas.read_csv(\"../data/processed_data/validation_set.csv\")\n",
    "testing_set = pandas.read_csv(\"../data/processed_data/testing_set.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the best baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import make_scorer\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"lg\": LogisticRegression(),\n",
    "    \"mnb\": MultinomialNB(),\n",
    "    \"svm\": LinearSVC(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection using Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start Jupyter in the environment 'Python 3.11.4 ('env': venv) (~/Desktop/test_project/env/bin/python)'. \n",
      "ImportError: cannot import name 'notebookapp' from 'notebook' (/Users/kirillklimushin/Desktop/test_project/env/lib/python3.11/site-packages/notebook/__init__.py) \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def balanced_recall(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "\n",
    "metric = make_scorer(balanced_recall, greater_is_better=True)\n",
    "\n",
    "feature_importances = {}\n",
    "\n",
    "X_train = training_set.drop(columns=['category'])\n",
    "Y_train = training_set['category']\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Computing Feature importances using Recursive Feature Elimination (RFE)\n",
    "    cv_results = RFECV(\n",
    "        estimator=model,\n",
    "        step=2,\n",
    "        min_features_to_select=4,\n",
    "        cv=StratifiedKFold(n_splits=5),\n",
    "        n_jobs=-1,\n",
    "        scoring=metric,\n",
    "    )\n",
    "    print('fitting %s model')\n",
    "    cv_results.fit(X_train, Y_train)\n",
    "    print('settings importances for model %s')\n",
    "    # storing output important features \n",
    "    feature_importances[model_name] = {\n",
    "        'important_features': cv_results.cv_results_\n",
    "    }\n",
    "\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning using Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    \"lg\": {\n",
    "        'penalty' : ['l1', 'l2', 'elasticnet', 'none'], # type of regularization\n",
    "        'C' : numpy.logspace(-4, 4, 20),  # C parameter\n",
    "        'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "        'max_iter' : [100, 1000,2500, 5000] # maximum number of iterations\n",
    "    },\n",
    "    \"mnb\": {\n",
    "        'alpha': [0.1, 0.5, 1.0, 1.5], # alpha regularization parameter\n",
    "        'fit_prior': [True, False]\n",
    "    },\n",
    "    \"svm\": {\n",
    "        'C': 1.0,  # Regularization strength\n",
    "        'loss': 'squared_hinge',  # Loss function\n",
    "        'dual': [True, False],  # Whether to solve the dual or primal problem\n",
    "        'fit_intercept': [True, False],  # Whether to calculate the intercept\n",
    "        'max_iter': 1000,  # Maximum number of iterations for the solver\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    score, best_model = train_model.fine_tune_model(\n",
    "        k_cross=5,\n",
    "        training_set=validation_set,\n",
    "        target_variable=\"category\",\n",
    "        hyperparams=hyperparams[model_name],\n",
    "        model=model,\n",
    "        loss_function_or_scorer_metric=metric,\n",
    "    )\n",
    "    output[model_name] = {\n",
    "        \"best_model\": best_model,\n",
    "        \"best_score\": score\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing output and choosing best baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picking the best model, based on a given score from the HP output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model = sorted(output, lambda model: model['best_score'], reverse=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing model using cross-validation on Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X, Y = testing_set.drop(columns=['category']), testing_set['category']\n",
    "cv = cross_validate(\n",
    "    estimator=chosen_model,\n",
    "    scoring=metric,\n",
    "    X=testing_set,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True)\n",
    ")\n",
    "print('test metric score: %s' % cv['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating model performance according to baseline metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('meets expected metric: ', metrics.AVERAGED_WEIGHTED_RECALL <= cv['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(chosen_model, open('../models/baseline_classifier.pkl', mode='wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
